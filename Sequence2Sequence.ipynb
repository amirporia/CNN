{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Encoder:\n",
        "\n",
        "The RNN class represents a basic RNN, with methods for the forward pass (forward) and step-wise recurrence (step).\n",
        "The encoder processes the input sequence and passes its last hidden state to the decoder.\n",
        "Decoder:\n",
        "\n",
        "The decoder is another RNN, initialized with the encoder’s final hidden state as its initial hidden state.\n",
        "It sequentially takes in each token from the target sequence and generates an output for each time step.\n",
        "Forward and Backward Pass:\n",
        "\n",
        "In the forward pass, the encoder processes the input sequence, and the decoder uses the encoder’s final hidden state to produce outputs for each time step in the target sequence.\n",
        "During backpropagation, the model computes gradients for the decoder and propagates errors backward through time for each hidden state.\n",
        "Training:\n",
        "\n",
        "The train method repeatedly calls the forward and backward passes over multiple epochs, updating weights based on gradients at each step."
      ],
      "metadata": {
        "id": "LhitcoqIWNBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54RiIjiXWLYi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Seq2Seq:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, learning_rate=0.01):\n",
        "        self.encoder = RNN(input_dim, hidden_dim)\n",
        "        self.decoder = RNN(output_dim, hidden_dim)\n",
        "        self.output_layer = np.random.randn(output_dim, hidden_dim) * 0.01\n",
        "        self.output_bias = np.zeros((output_dim, 1))\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, input_seq, target_seq):\n",
        "        # Encoder forward pass\n",
        "        encoder_hidden_states = self.encoder.forward(input_seq)\n",
        "\n",
        "        # Decoder forward pass (using last hidden state of encoder)\n",
        "        decoder_hidden = encoder_hidden_states[-1]\n",
        "        decoder_outputs = []\n",
        "        for target in target_seq:\n",
        "            decoder_hidden = self.decoder.step(target, decoder_hidden)\n",
        "            output = np.dot(self.output_layer, decoder_hidden) + self.output_bias\n",
        "            decoder_outputs.append(output)\n",
        "\n",
        "        return encoder_hidden_states, decoder_outputs\n",
        "\n",
        "    def backward(self, input_seq, target_seq, encoder_hidden_states, decoder_outputs):\n",
        "        # Initialize gradients\n",
        "        dW_out = np.zeros_like(self.output_layer)\n",
        "        dB_out = np.zeros_like(self.output_bias)\n",
        "\n",
        "        # Initialize the gradients for decoder hidden state\n",
        "        dh_decoder = np.zeros((self.hidden_dim, 1))\n",
        "\n",
        "        # Backprop through decoder time steps\n",
        "        for t in reversed(range(len(target_seq))):\n",
        "            dy = decoder_outputs[t] - target_seq[t].reshape(-1, 1)\n",
        "            dW_out += np.dot(dy, encoder_hidden_states[-1].T)\n",
        "            dB_out += dy\n",
        "\n",
        "            dh_decoder += np.dot(self.output_layer.T, dy)\n",
        "            dh_decoder = self.decoder.backward_step(dh_decoder)\n",
        "\n",
        "        # Backprop through encoder time steps\n",
        "        dh_encoder = dh_decoder\n",
        "        for t in reversed(range(len(input_seq))):\n",
        "            dh_encoder = self.encoder.backward_step(dh_encoder)\n",
        "\n",
        "        # Update weights\n",
        "        self.output_layer -= self.learning_rate * dW_out\n",
        "        self.output_bias -= self.learning_rate * dB_out\n",
        "\n",
        "    def train(self, input_seq, target_seq, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            encoder_hidden_states, decoder_outputs = self.forward(input_seq, target_seq)\n",
        "            self.backward(input_seq, target_seq, encoder_hidden_states, decoder_outputs)\n",
        "            if epoch % 10 == 0:\n",
        "                loss = sum((target.reshape(-1, 1) - output) ** 2 for target, output in zip(target_seq, decoder_outputs))\n",
        "                print(f'Epoch {epoch}, Loss: {np.sum(loss)}')\n",
        "\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.Wx = np.random.randn(hidden_dim, input_dim) * 0.01\n",
        "        self.Wh = np.random.randn(hidden_dim, hidden_dim) * 0.01\n",
        "        self.bh = np.zeros((hidden_dim, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.hidden_states = []\n",
        "        h_prev = np.zeros((self.hidden_dim, 1))\n",
        "        for x in inputs:\n",
        "            h_prev = self.step(x, h_prev)\n",
        "            self.hidden_states.append(h_prev)\n",
        "        return self.hidden_states\n",
        "\n",
        "    def step(self, x, h_prev):\n",
        "        h_next = np.tanh(np.dot(self.Wx, x.reshape(-1, 1)) + np.dot(self.Wh, h_prev) + self.bh)\n",
        "        return h_next\n",
        "\n",
        "    def backward_step(self, dh_next):\n",
        "        # Backpropagation for a single RNN step (time-step in sequence)\n",
        "        # This should update weights but here it returns `dh` for backprop to previous time steps\n",
        "        return np.dot(self.Wh.T, dh_next)\n",
        "\n",
        "# Example input and target sequences\n",
        "input_seq = [np.array([0.5, -0.2]), np.array([0.1, 0.8]), np.array([-0.3, 0.2])]\n",
        "target_seq = [np.array([0.1]), np.array([0.4]), np.array([-0.1])]\n",
        "\n",
        "# Initialize Seq2Seq model and train\n",
        "seq2seq = Seq2Seq(input_dim=2, hidden_dim=4, output_dim=1, learning_rate=0.01)\n",
        "seq2seq.train(input_seq, target_seq, epochs=100)\n"
      ]
    }
  ]
}